{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Chatura Samarasinghe<br> ELU, He innitialization, early stopping and transfer learning</b><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 28*28\n",
    "n_output_p1 = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "#neurons\n",
    "n_hidden = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Construction Phase</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(name=\"X\", dtype=tf.float32, shape=(None, n_input))\n",
    "y = tf.placeholder(name=\"y\", dtype=tf.int32, shape=(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.layers as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "below code is same as doing \n",
    "hidden1 = cl.fully_connected(X, n_hidden1, weights_initializer=he_init, activation_fn=tf.nn.elu)\n",
    "for all the layers \n",
    "'''\n",
    "# he initialization\n",
    "he_init = cl.variance_scaling_initializer()\n",
    "    \n",
    "hidden1 = tf.layers.dense(X, n_hidden, name = \"hidden1\", activation = tf.nn.elu, kernel_initializer = he_init)\n",
    "hidden2 = tf.layers.dense(hidden1, n_hidden, name = \"hidden2\", activation = tf.nn.elu, kernel_initializer = he_init)\n",
    "hidden3 = tf.layers.dense(hidden2, n_hidden, name = \"hidden3\", activation = tf.nn.elu, kernel_initializer = he_init)\n",
    "hidden4 = tf.layers.dense(hidden3, n_hidden, name = \"hidden4\", activation = tf.nn.elu, kernel_initializer = he_init)\n",
    "hidden5 = tf.layers.dense(hidden4, n_hidden, name = \"hidden5\", activation = tf.nn.elu, kernel_initializer = he_init)\n",
    "\n",
    "logits = tf.layers.dense(hidden5, n_output_p1, name = \"logits\", kernel_initializer = he_init)\n",
    "Y_proba = tf.nn.softmax(logits, name = \"Y_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss / cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "loss = tf.reduce_mean (cross_entropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Execution Phase </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images[mnist.train.labels < 5]\n",
    "y_train1 = mnist.train.labels[mnist.train.labels < 5]\n",
    "X_test1 = mnist.test.images[mnist.test.labels < 5]\n",
    "y_test1 = mnist.test.labels[mnist.test.labels < 5]\n",
    "X_valid1 = mnist.validation.images[mnist.validation.labels < 5]\n",
    "y_valid1 = mnist.validation.labels[mnist.validation.labels < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.128046\tBest loss: 0.128046\tAccuracy: 96.68%\n",
      "1\tValidation loss: 0.107482\tBest loss: 0.107482\tAccuracy: 96.83%\n",
      "2\tValidation loss: 0.289362\tBest loss: 0.107482\tAccuracy: 92.38%\n",
      "3\tValidation loss: 0.452124\tBest loss: 0.107482\tAccuracy: 85.11%\n",
      "4\tValidation loss: 0.389501\tBest loss: 0.107482\tAccuracy: 85.73%\n",
      "5\tValidation loss: 0.246087\tBest loss: 0.107482\tAccuracy: 93.75%\n",
      "6\tValidation loss: 0.174858\tBest loss: 0.107482\tAccuracy: 97.81%\n",
      "7\tValidation loss: 0.136970\tBest loss: 0.107482\tAccuracy: 97.38%\n",
      "8\tValidation loss: 0.126417\tBest loss: 0.107482\tAccuracy: 98.28%\n",
      "9\tValidation loss: 0.205518\tBest loss: 0.107482\tAccuracy: 96.52%\n",
      "10\tValidation loss: 0.828869\tBest loss: 0.107482\tAccuracy: 74.35%\n",
      "11\tValidation loss: 1.727138\tBest loss: 0.107482\tAccuracy: 20.91%\n",
      "12\tValidation loss: 1.766021\tBest loss: 0.107482\tAccuracy: 22.01%\n",
      "13\tValidation loss: 1.961557\tBest loss: 0.107482\tAccuracy: 20.91%\n",
      "14\tValidation loss: 1.649680\tBest loss: 0.107482\tAccuracy: 19.27%\n",
      "15\tValidation loss: 1.633523\tBest loss: 0.107482\tAccuracy: 20.91%\n",
      "16\tValidation loss: 1.710210\tBest loss: 0.107482\tAccuracy: 19.27%\n",
      "17\tValidation loss: 1.697299\tBest loss: 0.107482\tAccuracy: 18.73%\n",
      "18\tValidation loss: 1.721745\tBest loss: 0.107482\tAccuracy: 20.91%\n",
      "19\tValidation loss: 1.728258\tBest loss: 0.107482\tAccuracy: 19.27%\n",
      "20\tValidation loss: 1.651130\tBest loss: 0.107482\tAccuracy: 20.91%\n",
      "21\tValidation loss: 1.677234\tBest loss: 0.107482\tAccuracy: 20.91%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_trained_0to4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_trained_0to4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy: 97.43%\n"
     ]
    }
   ],
   "source": [
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        \n",
    "        n_batches = len(X_train1) // batch_size\n",
    "\n",
    "        for rnd_indices in np.array_split(rnd_idx, n_batches):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "        # using early stopping approach\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        \n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess,\"./mnist_trained_0to4\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            \n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "            \n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./mnist_trained_0to4\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Transfer Learning<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "# restore model\n",
    "restore_saver = tf.train.import_meta_graph(\"./mnist_trained_0to4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freezing lower layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data for mnist digits 5 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to subtract 5 from the labels because TensorFlow expects integers from 0 to n_classes-1.\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep only 100 instances per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_trained_0to4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_trained_0to4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.564859\tBest loss: 1.564859\tAccuracy: 42.67%\n",
      "1\tValidation loss: 1.379052\tBest loss: 1.379052\tAccuracy: 42.67%\n",
      "2\tValidation loss: 1.479223\tBest loss: 1.379052\tAccuracy: 39.33%\n",
      "3\tValidation loss: 1.478531\tBest loss: 1.379052\tAccuracy: 41.33%\n",
      "4\tValidation loss: 1.398207\tBest loss: 1.379052\tAccuracy: 36.67%\n",
      "5\tValidation loss: 1.379148\tBest loss: 1.379052\tAccuracy: 42.00%\n",
      "6\tValidation loss: 1.369241\tBest loss: 1.369241\tAccuracy: 43.33%\n",
      "7\tValidation loss: 1.398113\tBest loss: 1.369241\tAccuracy: 44.67%\n",
      "8\tValidation loss: 1.434817\tBest loss: 1.369241\tAccuracy: 36.67%\n",
      "9\tValidation loss: 1.376881\tBest loss: 1.369241\tAccuracy: 44.00%\n",
      "10\tValidation loss: 1.480938\tBest loss: 1.369241\tAccuracy: 43.33%\n",
      "11\tValidation loss: 1.380203\tBest loss: 1.369241\tAccuracy: 44.67%\n",
      "12\tValidation loss: 1.368326\tBest loss: 1.368326\tAccuracy: 46.00%\n",
      "13\tValidation loss: 1.413625\tBest loss: 1.368326\tAccuracy: 42.67%\n",
      "14\tValidation loss: 1.436285\tBest loss: 1.368326\tAccuracy: 41.33%\n",
      "15\tValidation loss: 1.412172\tBest loss: 1.368326\tAccuracy: 42.67%\n",
      "16\tValidation loss: 1.637665\tBest loss: 1.368326\tAccuracy: 44.00%\n",
      "17\tValidation loss: 1.458289\tBest loss: 1.368326\tAccuracy: 39.33%\n",
      "18\tValidation loss: 1.513103\tBest loss: 1.368326\tAccuracy: 40.67%\n",
      "19\tValidation loss: 1.385182\tBest loss: 1.368326\tAccuracy: 45.33%\n",
      "20\tValidation loss: 1.380922\tBest loss: 1.368326\tAccuracy: 37.33%\n",
      "21\tValidation loss: 1.397779\tBest loss: 1.368326\tAccuracy: 40.67%\n",
      "22\tValidation loss: 1.430222\tBest loss: 1.368326\tAccuracy: 42.67%\n",
      "23\tValidation loss: 1.413583\tBest loss: 1.368326\tAccuracy: 40.67%\n",
      "24\tValidation loss: 1.358943\tBest loss: 1.358943\tAccuracy: 44.67%\n",
      "25\tValidation loss: 1.434250\tBest loss: 1.358943\tAccuracy: 42.00%\n",
      "26\tValidation loss: 1.358776\tBest loss: 1.358776\tAccuracy: 45.33%\n",
      "27\tValidation loss: 1.396544\tBest loss: 1.358776\tAccuracy: 38.67%\n",
      "28\tValidation loss: 1.360424\tBest loss: 1.358776\tAccuracy: 42.00%\n",
      "29\tValidation loss: 1.559686\tBest loss: 1.358776\tAccuracy: 39.33%\n",
      "30\tValidation loss: 1.402969\tBest loss: 1.358776\tAccuracy: 40.67%\n",
      "31\tValidation loss: 1.414166\tBest loss: 1.358776\tAccuracy: 40.67%\n",
      "32\tValidation loss: 1.497035\tBest loss: 1.358776\tAccuracy: 37.33%\n",
      "33\tValidation loss: 1.377855\tBest loss: 1.358776\tAccuracy: 43.33%\n",
      "34\tValidation loss: 1.346665\tBest loss: 1.346665\tAccuracy: 46.00%\n",
      "35\tValidation loss: 1.417152\tBest loss: 1.346665\tAccuracy: 40.00%\n",
      "36\tValidation loss: 1.455387\tBest loss: 1.346665\tAccuracy: 40.00%\n",
      "37\tValidation loss: 1.487657\tBest loss: 1.346665\tAccuracy: 38.67%\n",
      "38\tValidation loss: 1.356711\tBest loss: 1.346665\tAccuracy: 43.33%\n",
      "39\tValidation loss: 1.343957\tBest loss: 1.343957\tAccuracy: 44.67%\n",
      "40\tValidation loss: 1.378812\tBest loss: 1.343957\tAccuracy: 41.33%\n",
      "41\tValidation loss: 1.401262\tBest loss: 1.343957\tAccuracy: 43.33%\n",
      "42\tValidation loss: 1.379169\tBest loss: 1.343957\tAccuracy: 41.33%\n",
      "43\tValidation loss: 1.561666\tBest loss: 1.343957\tAccuracy: 33.33%\n",
      "44\tValidation loss: 1.599644\tBest loss: 1.343957\tAccuracy: 37.33%\n",
      "45\tValidation loss: 1.350353\tBest loss: 1.343957\tAccuracy: 46.00%\n",
      "46\tValidation loss: 1.347257\tBest loss: 1.343957\tAccuracy: 45.33%\n",
      "47\tValidation loss: 1.436861\tBest loss: 1.343957\tAccuracy: 36.00%\n",
      "48\tValidation loss: 1.387591\tBest loss: 1.343957\tAccuracy: 44.67%\n",
      "49\tValidation loss: 1.473862\tBest loss: 1.343957\tAccuracy: 41.33%\n",
      "50\tValidation loss: 1.641535\tBest loss: 1.343957\tAccuracy: 42.00%\n",
      "51\tValidation loss: 1.380243\tBest loss: 1.343957\tAccuracy: 42.00%\n",
      "52\tValidation loss: 1.502082\tBest loss: 1.343957\tAccuracy: 35.33%\n",
      "53\tValidation loss: 1.445254\tBest loss: 1.343957\tAccuracy: 40.00%\n",
      "54\tValidation loss: 1.460843\tBest loss: 1.343957\tAccuracy: 42.00%\n",
      "55\tValidation loss: 1.515030\tBest loss: 1.343957\tAccuracy: 41.33%\n",
      "56\tValidation loss: 1.536801\tBest loss: 1.343957\tAccuracy: 41.33%\n",
      "57\tValidation loss: 1.378945\tBest loss: 1.343957\tAccuracy: 44.67%\n",
      "58\tValidation loss: 1.424753\tBest loss: 1.343957\tAccuracy: 39.33%\n",
      "59\tValidation loss: 1.502196\tBest loss: 1.343957\tAccuracy: 41.33%\n",
      "Early stopping!\n",
      "Total training time: 5.6s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy: 44.58%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./mnist_trained_0to4\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    t0 = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b><br> The low test accuracy is assumed to be a low score due to the small dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
